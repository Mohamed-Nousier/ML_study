{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(filepath_or_buffer=\"weatherAUS.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names =  df.columns\n",
    "column_names , f\"Number of columns is ==> {len(column_names)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Drop RISK_MM Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is already droped from this DB version \n",
    "# df.drop(['RISK_MM'], axis=1, inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# RainTomorrow ==> feature variable will be the output[y] that we need to pridict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Types of Variables \n",
    "* Categorical variables of dtype=='O'==> object\n",
    "* Numerical variables of dtype == 'f32,......'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical = [var for var in df.columns if df[var].dtype == 'O']\n",
    "\n",
    "print(f\"there are {len(Categorical)} Categorical variable\")\n",
    "print(f\"the Categorical variables are {Categorical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view Categorical variables\n",
    "df[Categorical].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Summary of categorical variables¶\n",
    "* There is a date variable. It is denoted by Date column.\n",
    "* There are 6 categorical variables. These are given by Location, WindGustDir, WindDir9am, WindDir3pm, RainToday and * RainTomorrow.\n",
    "* There are two binary categorical variables - RainToday and RainTomorrow.\n",
    "* RainTomorrow is the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Explore problems within categorical variables¶\n",
    "    First, I will explore the categorical variables.\n",
    "\n",
    "    Missing values in categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in categorical variables\n",
    "# For each Categorical feature , we will count the missing values for it \n",
    "df[Categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing Categorical variables only containing missing values\n",
    "\n",
    "cat1 = [var for var in Categorical if df[var].isnull().sum() != 0]\n",
    "\n",
    "print(f\"{df[cat1].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We can see that there are only 4 categorical variables in the dataset which contains missing values. These are WindGustDir, WindDir9am, WindDir3pm and RainToday.\n",
    "\n",
    "Frequency counts of categorical variables\n",
    "Now, I will check the frequency counts of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view frequency of categorical variables\n",
    "\n",
    "for var in Categorical:\n",
    "    print(df[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view frequency distribution of categorical variables\n",
    "\n",
    "for var in Categorical:\n",
    "    print(f\"{ df[var].value_counts() / np.float64(len(df)) }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Number of labels: cardinality\n",
    "The number of labels within a categorical variable is known as cardinality. A high number of labels within a variable is known as high cardinality. High cardinality may pose some serious problems in the machine learning model. So, I will check for high cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for cardinality in categorical variables\n",
    "\n",
    "for var in Categorical:\n",
    "    print(f\"{var} contains {len(df[var].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Feature engineering of feature Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "we can see the data type of 'Date' variable is object, i will parse Data[coded as an object] into datetime foramt so i can seperate the Date into year,month,day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Data variable ==> dates currently it is represented as string into datatime formate\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from Date\n",
    "\n",
    "# df[\"year\"] = np.int64(df[\"Date\"].dt.year)\n",
    "df[\"year\"] = df[\"Date\"].dt.year\n",
    "df['year'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Month from Date\n",
    "df[\"month\"] = df[\"Date\"].dt.month\n",
    "df[\"month\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day from Date\n",
    "df[\"day\"] = df[\"Date\"].dt.day\n",
    "df[\"day\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have added 3 columns to decompose the Data variable \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will remove Data variable since we replace it with year/month/day\n",
    "df.drop(columns=[\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will see the Date variable is no longer present anymore\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can see the year/month/day columns\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Explore Location variable¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of labels in Location variable\n",
    "print(f\"Location contains {len(df.Location.unique())} lables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check labels in location variable\n",
    "\n",
    "df.Location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check frequency distribution of values in Location variable\n",
    "df.Location.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## To convert catogerical variable into numerical one we will use one of the following:\n",
    "* Lable Encoding\n",
    "* One Hot Encoding\n",
    "* Dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 49 labels but we will drop the first and keep 48[we will be able to deduce the 49th] and we need the model to faulty[just a way for optimization] \n",
    "# so we can overcome overfitting\n",
    "# let's do One Hot Encoding of Location variable\n",
    "# get k-1 dummy variables after One Hot Encoding\n",
    "# preview the dataset with head() method\n",
    "\n",
    "\n",
    "pd.get_dummies(df.Location, drop_first=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-viewing the Data set again\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_categorical = [var for var in df.columns if df[var].dtype == 'O' ]\n",
    "print(f\"{remaining_categorical}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Explore WindGustDir variable¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of labels in WindGustDir variable\n",
    "print(f\"WindGustDir contains {len(df.WindGustDir.unique())} lables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the lables in WindGustDir variable\n",
    "df.WindGustDir.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check frequency distribution of values in WindGustDir variable\n",
    "df.WindGustDir.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do One Hot Encoding of WindGustDir variable\n",
    "# get k-1 dummy variables after One Hot Encoding\n",
    "# preview the dataset with head() method\n",
    "\n",
    "\n",
    "dummies = pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True)\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1: axis=0 (Summing DOWN)\n",
    "# This counts how many times 'N', 'S', 'W', or 'NaN' occurred. similiar to ==>[df.WindGustDir.value_counts()]\n",
    "col_sums = dummies.sum(axis=0)\n",
    "print(\"--- sum(axis=0) : Column Counts ---\")\n",
    "print(col_sums)\n",
    "\n",
    "# CASE 2: axis=1 (Summing ACROSS)\n",
    "# This sums the row. Since it's one-hot encoded,\n",
    "# it confirms that each row has exactly one entry marked as 1.\n",
    "row_sums = dummies.sum(axis=1)\n",
    "print(\"\\n--- sum(axis=1) : Row Totals ---\")\n",
    "print(row_sums)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "we have NaN = 10326(missing values) needed to fixed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{[var for var in df.columns if df[var].dtype == 'O']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## Explore WindDir9am variable¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of labels in WindDir9am variable\n",
    "print(f\"WindGustDir contains {len(df.WindDir9am.unique())} lables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the lables\n",
    "df.WindDir9am.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the frequence distribution of the lables inside WindDir9am feature\n",
    "df.WindDir9am.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do One Hot Encoding of WindDir9am variable\n",
    "# get k-1 dummy variables after One Hot Encoding\n",
    "# preview the dataset with head() method\n",
    "\n",
    "\n",
    "WindDir9am_dummies =  pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True).head()\n",
    "WindDir9am_dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is similair to .count_values()\n",
    "WindDir9am_dummies.sum(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Explore RainToday variable¶\n",
    "   this is the output lable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of labels in RainToday variable\n",
    "print(f\"WindGustDir contains {len(df.RainToday.unique())} lables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the lables names\n",
    "df.RainToday.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribuation for the lables inside the reponse feature\n",
    "df.RainToday.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RainToday_dummies = pd.get_dummies(df.RainToday, dummy_na=True)\n",
    "# \tNo\tYes\tNaN\n",
    "# 0\tTrue\tFalse\tFalse\n",
    "# 1\tTrue\tFalse\tFalse\n",
    "# 2\tTrue\tFalse\tFalse\n",
    "# 3\tTrue\tFalse\tFalse\n",
    "# 4\tTrue\tFalse\tFalse\n",
    "RainToday_dummies = pd.get_dummies(df.RainToday,drop_first=True, dummy_na=True)\n",
    "RainToday_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "RainToday_dummies.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "## Exploring the Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [var for var in df.columns if df[var].dtype != 'O']\n",
    "\n",
    "print(f\"Number of numerical features is {len(numerical)}\")\n",
    "print(f\"Numerical features is {numerical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the numerical variables \n",
    "df[numerical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values in the numerical values\n",
    "df[numerical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veiw summary statistics in numerical values\n",
    "\n",
    "# df[numerical].describe()\n",
    "#Round the precision number for better view [representation] \n",
    "round(df[numerical].describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
